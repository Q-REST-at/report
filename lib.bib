@misc{AutomatedAlignmentSoftware,
  title = {Automated {{Alignment}} of {{Software Requirements}} and {{Test Cases}}},
  urldate = {2025-01-30},
  howpublished = {https://odr.chalmers.se/items/fd6c5b34-b52a-464d-97d4-b3ff5dc6cb37}
}

@inproceedings{barmiAlignmentRequirementsSpecification2011,
  title = {Alignment of {{Requirements Specification}} and {{Testing}}: {{A Systematic Mapping Study}}},
  shorttitle = {Alignment of {{Requirements Specification}} and {{Testing}}},
  booktitle = {2011 {{IEEE Fourth International Conference}} on {{Software Testing}}, {{Verification}} and {{Validation Workshops}}},
  author = {Barmi, Zeinab Alizadeh and Ebrahimi, Amir Hossein and Feldt, Robert},
  year = {2011},
  month = mar,
  pages = {476--485},
  doi = {10.1109/ICSTW.2011.58},
  urldate = {2025-02-03},
  keywords = {Data mining,Joining processes,Programming,Software,Systematics,Testing,Web services}
}

@article{bjarnasonChallengesPracticesAligning2014,
  title = {Challenges and Practices in Aligning Requirements with Verification and Validation: A Case Study of Six Companies},
  shorttitle = {Challenges and Practices in Aligning Requirements with Verification and Validation},
  author = {Bjarnason, Elizabeth and Runeson, Per and Borg, Markus and Unterkalmsteiner, Michael and Engstr{\"o}m, Emelie and Regnell, Bj{\"o}rn and Sabaliauskaite, Giedre and Loconsole, Annabella and Gorschek, Tony and Feldt, Robert},
  year = {2014},
  month = dec,
  journal = {Empirical Software Engineering},
  volume = {19},
  number = {6},
  pages = {1809--1855},
  issn = {1573-7616},
  doi = {10.1007/s10664-013-9263-y},
  urldate = {2025-02-03},
  langid = {english},
  keywords = {Alignment,Case study,Requirements engineering,Testing,Validation,Verification}
}

@misc{chenEfficientQATEfficientQuantizationAware2024,
  title = {{{EfficientQAT}}: {{Efficient Quantization-Aware Training}} for {{Large Language Models}}},
  shorttitle = {{{EfficientQAT}}},
  author = {Chen, Mengzhao and Shao, Wenqi and Xu, Peng and Wang, Jiahao and Gao, Peng and Zhang, Kaipeng and Luo, Ping},
  year = {2024},
  month = oct,
  number = {arXiv:2407.11062},
  eprint = {2407.11062},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2407.11062},
  urldate = {2025-02-03},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning}
}

@misc{dettmersSpQRSparseQuantizedRepresentation2023,
  title = {{{SpQR}}: {{A Sparse-Quantized Representation}} for {{Near-Lossless LLM Weight Compression}}},
  shorttitle = {{{SpQR}}},
  author = {Dettmers, Tim and Svirschevski, Ruslan and Egiazarian, Vage and Kuznedelev, Denis and Frantar, Elias and Ashkboos, Saleh and Borzunov, Alexander and Hoefler, Torsten and Alistarh, Dan},
  year = {2023},
  month = jun,
  number = {arXiv:2306.03078},
  eprint = {2306.03078},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2306.03078},
  urldate = {2025-02-03},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning}
}

@misc{frantarGPTQAccuratePostTraining2023,
  title = {{{GPTQ}}: {{Accurate Post-Training Quantization}} for {{Generative Pre-trained Transformers}}},
  shorttitle = {{{GPTQ}}},
  author = {Frantar, Elias and Ashkboos, Saleh and Hoefler, Torsten and Alistarh, Dan},
  year = {2023},
  month = mar,
  number = {arXiv:2210.17323},
  eprint = {2210.17323},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2210.17323},
  urldate = {2025-02-03},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning}
}

@inproceedings{gomesdeoliveiranetoChallengesAligningRequirements2017,
  title = {Challenges of {{Aligning Requirements Engineering}} and {{System Testing}} in {{Large-Scale Agile}}: {{A Multiple Case Study}}},
  shorttitle = {Challenges of {{Aligning Requirements Engineering}} and {{System Testing}} in {{Large-Scale Agile}}},
  booktitle = {2017 {{IEEE}} 25th {{International Requirements Engineering Conference Workshops}} ({{REW}})},
  author = {Gomes De Oliveira Neto, Francisco and Horkoff, Jennifer and Knauss, Eric and Kasauli, Rashidah and Liebel, Grischa},
  year = {2017},
  month = sep,
  pages = {315--322},
  doi = {10.1109/REW.2017.33},
  urldate = {2025-02-03},
  keywords = {Companies,Conferences,large-scale agile system development,requirements engineering,Requirements engineering,Software,Stakeholders,System testing,system testing alignment}
}

@article{linAWQActivationawareWeight2024,
  title = {{{AWQ}}: {{Activation-aware Weight Quantization}} for {{On-Device LLM Compression}} and {{Acceleration}}},
  shorttitle = {{{AWQ}}},
  author = {Lin, Ji and Tang, Jiaming and Tang, Haotian and Yang, Shang and Chen, Wei-Ming and Wang, Wei-Chen and Xiao, Guangxuan and Dang, Xingyu and Gan, Chuang and Han, Song},
  year = {2024},
  month = may,
  journal = {Proceedings of Machine Learning and Systems},
  volume = {6},
  pages = {87--100},
  urldate = {2025-02-02},
  langid = {english}
}

@misc{liuEmergentAbilitiesExist2023,
  title = {Do {{Emergent Abilities Exist}} in {{Quantized Large Language Models}}: {{An Empirical Study}}},
  shorttitle = {Do {{Emergent Abilities Exist}} in {{Quantized Large Language Models}}},
  author = {Liu, Peiyu and Liu, Zikang and Gao, Ze-Feng and Gao, Dawei and Zhao, Wayne Xin and Li, Yaliang and Ding, Bolin and Wen, Ji-Rong},
  year = {2023},
  month = jul,
  number = {arXiv:2307.08072},
  eprint = {2307.08072},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2307.08072},
  urldate = {2025-01-30},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language}
}

@misc{naveedComprehensiveOverviewLarge2024,
  title = {A {{Comprehensive Overview}} of {{Large Language Models}}},
  author = {Naveed, Humza and Khan, Asad Ullah and Qiu, Shi and Saqib, Muhammad and Anwar, Saeed and Usman, Muhammad and Akhtar, Naveed and Barnes, Nick and Mian, Ajmal},
  year = {2024},
  month = oct,
  number = {arXiv:2307.06435},
  eprint = {2307.06435},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2307.06435},
  urldate = {2025-02-03},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language}
}

@inproceedings{rasleyDeepSpeedSystemOptimizations2020,
  title = {{{DeepSpeed}}: {{System Optimizations Enable Training Deep Learning Models}} with {{Over}} 100 {{Billion Parameters}}},
  shorttitle = {{{DeepSpeed}}},
  booktitle = {Proceedings of the 26th {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} \& {{Data Mining}}},
  author = {Rasley, Jeff and Rajbhandari, Samyam and Ruwase, Olatunji and He, Yuxiong},
  year = {2020},
  month = aug,
  series = {{{KDD}} '20},
  pages = {3505--3506},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3394486.3406703},
  urldate = {2025-02-03},
  isbn = {978-1-4503-7998-4}
}

@article{unterkalmsteinerTaxonomyRequirementsEngineering2014,
  title = {A Taxonomy for Requirements Engineering and Software Test Alignment},
  author = {Unterkalmsteiner, M. and Feldt, R. and Gorschek, T.},
  year = {2014},
  month = apr,
  journal = {ACM Trans. Softw. Eng. Methodol.},
  volume = {23},
  number = {2},
  pages = {16:1--16:38},
  issn = {1049-331X},
  doi = {10.1145/2523088},
  urldate = {2025-02-03},
}

@inproceedings{xiaoSmoothQuantAccurateEfficient2023,
  title = {{{SmoothQuant}}: {{Accurate}} and {{Efficient Post-Training Quantization}} for {{Large Language Models}}},
  shorttitle = {{{SmoothQuant}}},
  booktitle = {Proceedings of the 40th {{International Conference}} on {{Machine Learning}}},
  author = {Xiao, Guangxuan and Lin, Ji and Seznec, Mickael and Wu, Hao and Demouth, Julien and Han, Song},
  year = {2023},
  month = jul,
  pages = {38087--38099},
  publisher = {PMLR},
  issn = {2640-3498},
  urldate = {2025-02-03},
  langid = {english}
}

@misc{zhangWhenScalingMeets2024,
  title = {When {{Scaling Meets LLM Finetuning}}: {{The Effect}} of {{Data}}, {{Model}} and {{Finetuning Method}}},
  shorttitle = {When {{Scaling Meets LLM Finetuning}}},
  author = {Zhang, Biao and Liu, Zhongtao and Cherry, Colin and Firat, Orhan},
  year = {2024},
  month = feb,
  number = {arXiv:2402.17193},
  eprint = {2402.17193},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.17193},
  urldate = {2025-02-03},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning}
}

@article{zhuSurveyModelCompression2024,
  title = {A {{Survey}} on {{Model Compression}} for {{Large Language Models}}},
  author = {Zhu, Xunyu and Li, Jian and Liu, Yong and Ma, Can and Wang, Weiping},
  year = {2024},
  month = nov,
  journal = {Transactions of the Association for Computational Linguistics},
  volume = {12},
  pages = {1556--1577},
  issn = {2307-387X},
  doi = {10.1162/tacl_a_00704},
  urldate = {2025-02-03},
}

@article{vaswaniAttentionAllYou2017,
  title = {Attention Is All You Need},
  author = {Vaswani, A.},
  year = {2017},
  journal = {Advances in Neural Information Processing Systems},
  urldate = {2025-02-03}
}

@incollection{jonesNaturalLanguageProcessing1994,
  title = {Natural {{Language Processing}}: {{A Historical Review}}},
  shorttitle = {Natural {{Language Processing}}},
  booktitle = {Current {{Issues}} in {{Computational Linguistics}}: {{In Honour}} of {{Don Walker}}},
  author = {Jones, Karen Sparck},
  editor = {Zampolli, Antonio and Calzolari, Nicoletta and Palmer, Martha},
  year = {1994},
  pages = {3--16},
  publisher = {Springer Netherlands},
  address = {Dordrecht},
  doi = {10.1007/978-0-585-35958-8_1},
  urldate = {2025-02-03},
  isbn = {978-0-585-35958-8},
  langid = {english},
  keywords = {Ambiguity Resolution,Machine Translation,Natural Language Processing,Natural Language Processing System,World Knowledge}
}

@misc{dettmers2022llmint88bitmatrixmultiplication,
      title={LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale}, 
      author={Tim Dettmers and Mike Lewis and Younes Belkada and Luke Zettlemoyer},
      year={2022},
      eprint={2208.07339},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2208.07339}, 
}

@inproceedings{barmi_alignment_2011,
	title = {Alignment of {Requirements} {Specification} and {Testing}: {A} {Systematic} {Mapping} {Study}},
	shorttitle = {Alignment of {Requirements} {Specification} and {Testing}},
	url = {https://ieeexplore.ieee.org/abstract/document/5954452},
	doi = {10.1109/ICSTW.2011.58},
	urldate = {2025-02-03},
	booktitle = {2011 {IEEE} {Fourth} {International} {Conference} on {Software} {Testing}, {Verification} and {Validation} {Workshops}},
	author = {Barmi, Zeinab Alizadeh and Ebrahimi, Amir Hossein and Feldt, Robert},
	month = mar,
	year = {2011},
	keywords = {Data mining, Joining processes, Programming, Software, Systematics, Testing, Web services},
	pages = {476--485},
}

@misc{li2023nuanceskeyunlockingchatgpt,
      title={Nuances are the Key: Unlocking ChatGPT to Find Failure-Inducing Tests with Differential Prompting}, 
      author={Tsz-On Li and Wenxi Zong and Yibo Wang and Haoye Tian and Ying Wang and Shing-Chi Cheung and Jeff Kramer},
      year={2023},
      eprint={2304.11686},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2304.11686}, 
}

@misc{li2024largelanguagemodelstest,
      title={Large Language Models as Test Case Generators: Performance Evaluation and Enhancement}, 
      author={Kefan Li and Yuan Yuan},
      year={2024},
      eprint={2404.13340},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2404.13340}, 
}

@misc{egashiraExploitingLLMQuantization2024,
  title = {Exploiting {{LLM Quantization}}},
  author = {Egashira, Kazuki and Vero, Mark and Staab, Robin and He, Jingxuan and Vechev, Martin},
  year = {2024},
  month = nov,
  number = {arXiv:2405.18137},
  eprint = {2405.18137},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2405.18137},
  urldate = {2025-02-04},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Cryptography and Security,Computer Science - Machine Learning}
}

@misc{minaeeLargeLanguageModels2024,
  title = {Large {{Language Models}}: {{A Survey}}},
  shorttitle = {Large {{Language Models}}},
  author = {Minaee, Shervin and Mikolov, Tomas and Nikzad, Narjes and Chenaghlu, Meysam and Socher, Richard and Amatriain, Xavier and Gao, Jianfeng},
  year = {2024},
  month = feb,
  number = {arXiv:2402.06196},
  eprint = {2402.06196},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.06196},
  urldate = {2025-02-03},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language}
}

@inproceedings{bhatiaUnitTestGeneration2024,
  title = {Unit {{Test Generation}} Using {{Generative AI}} : {{A Comparative Performance Analysis}} of {{Autogeneration Tools}}},
  shorttitle = {Unit {{Test Generation}} Using {{Generative AI}}},
  booktitle = {Proceedings of the 1st {{International Workshop}} on {{Large Language Models}} for {{Code}}},
  author = {Bhatia, Shreya and Gandhi, Tarushi and Kumar, Dhruv and Jalote, Pankaj},
  year = {2024},
  month = sep,
  series = {{{LLM4Code}} '24},
  pages = {54--61},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3643795.3648396},
  urldate = {2025-02-07},
  abstract = {Generating unit tests is a crucial task in software development, demanding substantial time and effort from programmers. The advent of Large Language Models (LLMs) introduces a novel avenue for unit test script generation. This research aims to experimentally investigate the effectiveness of LLMs, specifically exemplified by ChatGPT, for generating unit test scripts for Python programs, and how the generated test cases compare with those generated by an existing unit test generator (Pynguin). For experiments, we consider three types of code units: 1) Procedural scripts, 2) Function-based modular code, and 3) Class-based code. The generated test cases are evaluated based on criteria such as coverage, correctness, and readability. Our results show that ChatGPT's performance is comparable with Pynguin in terms of coverage, though for some cases its performance is superior to Pynguin. We also find that about a third of assertions generated by ChatGPT for some categories were incorrect. Our results also show that there is minimal overlap in missed statements between ChatGPT and Pynguin, thus, suggesting that a combination of both tools may enhance unit test generation performance. Finally, in our experiments, prompt engineering improved ChatGPT's performance, achieving a much higher coverage.*These authors contributed equally.},
  isbn = {979-8-4007-0579-3}
}

@inproceedings{karhapaa_what_2017,
	address = {New York, NY, USA},
	series = {{EASE} '17},
	title = {What {Do} {We} {Know} about {Alignment} of {Requirements} {Engineering} and {Software} {Testing}?},
	isbn = {978-1-4503-4804-1},
	url = {https://dl.acm.org/doi/10.1145/3084226.3084265},
	doi = {10.1145/3084226.3084265},
	abstract = {Context: The alignment of different software engineering activities for coordinated functioning and optimized product development is of great importance, particularly in industrial-scale development. The link between intermediate activities has been researched extensively, but the link between requirements engineering (RE) and software testing (ST) is a relatively less explored area.Objective: The objective of this study is to aggregate, structure, and classify all existing research regarding alignment of RE and ST published by the end of 2015.Method: We conducted a systematic mapping study (SMS) and aggregated all studies relevant to our scope. The primary studies are analyzed in terms of publication trend, focus area, i.e., how alignment is supported, the application domain and benefits and challenges, methodological data, and scientific rigor and industrial relevance.Results: There is a growing interest towards the topic. Several different techniques have been identified to improve RE and ST alignment. Test generation from requirements specification has received most attention. Alignment of RE and ST is particularly important for large safety-critical domains. While many challenges have been reported, the supporting evidence for benefits is scarce. Frameworks/methods/techniques is the most frequent contribution type. Solution proposal and evaluation research were the most frequently applied research type. Case study research was the most frequently applied research method, however, almost half of the studies did not clearly report any research method.Conclusion: Despite the numerous approaches that are proposed, it is not clear what approach is suitable in what context and why. To support industry in RE and ST alignment, guidelines and tool support are needed. The supporting evidence for claimed benefits is very limited. Overall, the research area is in its early stages and an increase in both the number and rigor of empirical studies are required.},
	urldate = {2025-02-06},
	booktitle = {Proceedings of the 21st {International} {Conference} on {Evaluation} and {Assessment} in {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Karhapää, Pertti and Haghighatkhah, Alireza and Oivo, Markku},
	month = jun,
	year = {2017},
	pages = {354--363},
}

@mastersthesis{ivarsson2023automated,
    author = {Ivarsson, Samuel and Setterström, Jesper},
    title = {Automated Alignment of Software Requirements and Test Cases},
    school = {Chalmers University of Technology},
    year = {2023},
    month = {August},
    url = {http://hdl.handle.net/20.500.12380/306739},
    abstract = {Software testing can be expensive, but there are numerous tools available to enhance its efficiency. Nevertheless, certain areas still lack adequate technology. To address this, we conducted a qualitative study to identify shortcomings in existing tools and determine what features are needed in new ones. Through Thematic Analysis of the interviews conducted, we discovered that system-level testing stands out as an area in need of improvement, with a particular emphasis on the importance of well-defined requirements for effective testing. In light of this, we propose the development of a tool that assists testers in aligning their tests with requirements and generates suggestions for new tests using a powerful Large Language Model (LLM). The tool demonstrated great efficacy in terms of accuracy and recall, achieving an average of 86.394% each. It also provided valuable suggestions for testing approaches related to requirements. However, we observed limitations in its ability to achieve perfect alignment between requirements and test cases, as it showed a tendency for false positives. This led to the tool having an average precision of 45.582%. Moreover, the tool exhibited high efficiency when handling smaller input sizes. However, as the input size increased, we noticed a more than linear growth in analysis time, suggesting potential scalability challenges.},
}